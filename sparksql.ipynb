{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark is an existing SparkSession\n",
    "df = spark.read.json(\"/Users/sravanthi/Documents/Sandbox/spark-2.4.4-bin-hadoop2.7/python/test_support/sql/people.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Displays the content of the DataFrame to stdout\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.printSchema()\n",
    "\n",
    "from pyspark.sql.functions import when   \n",
    "\n",
    "df = df.withColumn('Name', \n",
    "                     F.when(df['name'] == \"Michael\", \"MICHAEL\")\n",
    "                     .when(df['name'] == \"Andy\", \"ANDY\")\n",
    "                     .otherwise(0))\n",
    "# newdf = df.withColumn('name', F.when(df['name'] == \"Andy\", \"ANDY\"))\n",
    "# newdf = df.withColumn('name', F.when(df['name'] == \"Justin\", \"JUSTIN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   Name|\n",
      "+----+-------+\n",
      "|null|MICHAEL|\n",
      "|  30|   ANDY|\n",
      "|  19|      0|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(age=None, name='Michael'), Row(age=30, name='Andy')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------+\n",
      "|summary|               age|   name|\n",
      "+-------+------------------+-------+\n",
      "|  count|                 2|      3|\n",
      "|   mean|              24.5|   null|\n",
      "| stddev|7.7781745930520225|   null|\n",
      "|    min|                19|   Andy|\n",
      "|    max|                30|Michael|\n",
      "+-------+------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+\n",
      "|   name|(age + 1)|\n",
      "+-------+---------+\n",
      "|Michael|     null|\n",
      "|   Andy|       31|\n",
      "| Justin|       20|\n",
      "+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select everybody, but increment the age by 1\n",
    "df.select(df['name'], df['age'] + 1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "|age|name|\n",
      "+---+----+\n",
      "| 30|Andy|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select people older than 21\n",
    "df.filter(df['age'] > 21).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "| age|count|\n",
      "+----+-----+\n",
      "|  19|    1|\n",
      "|null|    1|\n",
      "|  30|    1|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count people by age\n",
    "df.groupBy(\"age\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running SQL Queries Programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Register the DataFrame as a SQL temporary view\n",
    "df.createOrReplaceTempView(\"people\")\n",
    "\n",
    "sqlDF = spark.sql(\"SELECT * FROM people\")\n",
    "sqlDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PythonRDD[113] at RDD at PythonRDD.scala:53\n"
     ]
    }
   ],
   "source": [
    "# Import data types\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# Load a text file and convert each line to a Row.\n",
    "lines = sc.textFile(\"/Users/sravanthi/Documents/Sandbox/spark-2.4.4-bin-hadoop2.7/examples/src/main/resources/people.txt\")\n",
    "parts = lines.map(lambda l: l.split(\",\"))\n",
    "# Each line is converted to a tuple.\n",
    "people = parts.map(lambda p: (p[0], p[1].strip()))\n",
    "print(people)\n",
    "# The schema is encoded in a string.\n",
    "schemaString = \"name age\"\n",
    "\n",
    "fields = [StructField(field_name, StringType(), True) for field_name in schemaString.split()]\n",
    "schema = StructType(fields)\n",
    "\n",
    "# Apply the schema to the RDD.\n",
    "schemaPeople = spark.createDataFrame(people, schema)\n",
    "\n",
    "# Michael, 29\n",
    "# Andy, 30\n",
    "# Justin, 19\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|   name|age|\n",
      "+-------+---+\n",
      "|Michael| 29|\n",
      "|   Andy| 30|\n",
      "| Justin| 19|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creates a temporary view using the DataFrame\n",
    "schemaPeople.createOrReplaceTempView(\"people\")\n",
    "\n",
    "# SQL can be run over DataFrames that have been registered as a table.\n",
    "results = spark.sql(\"SELECT * FROM people\")\n",
    "\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise - Mental Health Tech Survey :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveyDf = spark.read.options(header=\"true\",\\\n",
    "                              inferSchema=\"true\",\\\n",
    "                              nullValue=\"NA\",\\\n",
    "                              timestampFormat=\"yyyy-MM-dd'T'HH:mm:ss\",\\\n",
    "                              mode=\"failfast\")\\\n",
    "                             .csv(\"/Users/sravanthi/Documents/Sandbox/spark/survey.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1259"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surveyDf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, Timestamp: string, Age: string, Gender: string, Country: string, state: string, self_employed: string, family_history: string, treatment: string, work_interfere: string, no_employees: string, remote_work: string, tech_company: string, benefits: string, care_options: string, wellness_program: string, seek_help: string, anonymity: string, leave: string, mental_health_consequence: string, phys_health_consequence: string, coworkers: string, supervisor: string, mental_health_interview: string, phys_health_interview: string, mental_vs_physical: string, obs_consequence: string, comments: string]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surveyDf.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate and display the count of people (gender wise) who have taken treatment for mental health condition.\n",
    "> 2. What is the average age of participants (gender wise) from the country \"Canada\"?\n",
    "> 3. What is the youngest age of participant from United Kingdom?\n",
    "> 4. List the count of participants who work for tech company , country wise?\n",
    "> 5. List the top 10 participants by age who had family history of mental health issues and had taken the treament."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import when   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveyDf = surveyDf.withColumn(\"Gender\",\n",
    "                                F.when(surveyDf[\"Gender\"] == \"Cis Female\", \"Female\")\n",
    "                                .when(surveyDf[\"Gender\"] == \"cis-female/femme\", \"Female\")\n",
    "                                .when(surveyDf[\"Gender\"] == \"Woman\", \"Female\")\n",
    "                                .when(surveyDf[\"Gender\"] == \"F\", \"Female\")\n",
    "                                .when(surveyDf[\"Gender\"] == \"Femake\", \"Female\")\n",
    "                                .when(surveyDf[\"Gender\"] == \"femail\", \"Female\")\n",
    "                                .when(surveyDf[\"Gender\"] == \"Female (cis)\", \"Female\")\n",
    "                                .when(surveyDf[\"Gender\"] == \"female\", \"Female\")\n",
    "                                .when(surveyDf[\"Gender\"] == \"Cis Male\", \"Male\")\n",
    "                                .when(surveyDf[\"Gender\"] == \"Cis Man\", \"Male\")\n",
    "                                .when(surveyDf[\"Gender\"] == \"Guy (-ish) ^_^\", \"Male\")\n",
    "                                .when(surveyDf[\"Gender\"] == \"M\", \"Male\")\n",
    "                                .when(surveyDf[\"Gender\"] == \"Mail\", \"Male\")\n",
    "                                .when(surveyDf[\"Gender\"] == \"maile\", \"Male\")\n",
    "                                .when(surveyDf[\"Gender\"] == \"Make\", \"Male\")\n",
    "                                .when(surveyDf[\"Gender\"] == \"Mal\", \"Male\")\n",
    "                                .when(surveyDf[\"Gender\"] == \"Male (CIS)\", \"Male\")\n",
    "                                .when(surveyDf[\"Gender\"] == \"Male-ish\", \"Male\")\n",
    "                                .when(surveyDf[\"Gender\"] == \"Malr\", \"Male\")\n",
    "                                .when(surveyDf[\"Gender\"] == \"Man\", \"Male\")\n",
    "                                .when(surveyDf[\"Gender\"] == \"msle\", \"Male\")\n",
    "                                .when(surveyDf[\"Gender\"] == \"Male\", \"Male\")\n",
    "                                .when(surveyDf[\"Gender\"] == \"male\", \"Male\")\n",
    "                                .otherwise(\"No gender\")\n",
    "                                \n",
    "                                )\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+\n",
      "|   gender|count(gender)|\n",
      "+---------+-------------+\n",
      "|No gender|           35|\n",
      "|   Female|           24|\n",
      "|     Male|          115|\n",
      "+---------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Register the DataFrame as a SQL temporary view\n",
    "surveyDf.createOrReplaceTempView(\"surveydf\")\n",
    "# spark.sql(\"select unique(gender) from surveydf\")\n",
    "sqlsurveyDf = spark.sql('select gender,count(gender) from surveyDf where mental_health_consequence == \"Yes\" and treatment = \"Yes\" group by gender ')\n",
    "sqlsurveyDf.show()\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|   gender|           avg_age|\n",
      "+---------+------------------+\n",
      "|No gender|             30.25|\n",
      "|   Female|              28.6|\n",
      "|     Male|29.181818181818183|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What is the average age of participants (gender wise) from the country \"Canada\"?\n",
    "\n",
    "sqlsurveyDf1 = spark.sql('select gender, Avg(Age) as avg_age from surveyDf where Country == \"Canada\" group by gender ')\n",
    "sqlsurveyDf1.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---+\n",
      "|       Country|Age|\n",
      "+--------------+---+\n",
      "|United Kingdom| 18|\n",
      "+--------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What is the youngest age of participant from United Kingdom?\n",
    "\n",
    "sqlsurveyDf2 = spark.sql('select Country,Age from surveyDf where Country == \"United Kingdom\" and Age > 0 order by Age limit 1 ')\n",
    "sqlsurveyDf2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+\n",
      "|      country|Count_participants|\n",
      "+-------------+------------------+\n",
      "|       Russia|                 3|\n",
      "|       Sweden|                 7|\n",
      "|  Philippines|                 1|\n",
      "|    Singapore|                 4|\n",
      "|      Germany|                40|\n",
      "|       France|                12|\n",
      "|       Greece|                 2|\n",
      "|      Belgium|                 3|\n",
      "|      Finland|                 2|\n",
      "|United States|               611|\n",
      "|        India|                 9|\n",
      "|        China|                 1|\n",
      "|      Croatia|                 2|\n",
      "|      Nigeria|                 1|\n",
      "|        Italy|                 5|\n",
      "|       Norway|                 1|\n",
      "|        Spain|                 1|\n",
      "|      Denmark|                 2|\n",
      "|      Ireland|                26|\n",
      "|     Thailand|                 1|\n",
      "+-------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List the count of participants who work for tech company , country wise?\n",
    "\n",
    "sqlsurveyDf3 = spark.sql('select country, count(*) as Count_participants  from surveyDf where tech_company == \"Yes\" group by country')\n",
    "sqlsurveyDf3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|age|\n",
      "+---+\n",
      "| -1|\n",
      "|  8|\n",
      "| 21|\n",
      "| 22|\n",
      "| 22|\n",
      "| 23|\n",
      "| 23|\n",
      "| 24|\n",
      "| 24|\n",
      "| 24|\n",
      "| 24|\n",
      "| 25|\n",
      "| 25|\n",
      "| 25|\n",
      "| 25|\n",
      "| 25|\n",
      "| 25|\n",
      "| 25|\n",
      "| 25|\n",
      "| 26|\n",
      "+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List the top 10 participants by age who had family history of mental health issues and had taken the treament.\n",
    " \n",
    "sqlsurveyDf3 = spark.sql('select age from surveyDf where family_history == \"Yes\" and mental_health_consequence == \"Yes\" and treatment = \"Yes\" order by age ')\n",
    "sqlsurveyDf3.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
